{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df = pd.read_csv('00_keywords.csv')\n",
    "keyword_list = keyword_df['Keywords'].values.tolist()\n",
    "number_of_results_list = keyword_df['Number of results'].values.tolist()\n",
    "language_code_list = keyword_df['Language Code'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchpage scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'ua_file.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_proxy = lines[int(idx)]\n",
    "            random_ua = random_proxy.rstrip()\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_link():\n",
    "    user_agent = get_random_ua()\n",
    "    search_term = keyword_list[number_inputs]\n",
    "    number_results = number_of_results_list[number_inputs]\n",
    "    language_code = language_code_list[number_inputs]\n",
    "    headers = {\n",
    "            'user-agent': user_agent,\n",
    "             'referrer': 'https://google.com',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Pragma': 'no-cache',\n",
    "        }\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    "    google_url = 'https://www.google.com/search?q={}&num={}&hl={}'.format(escaped_search_term, number_results, language_code)\n",
    "    delays = [7, 4, 6, 2, 10, 19]\n",
    "    delay = np.random.choice(delays)\n",
    "    time.sleep(delay)\n",
    "    response = requests.get(google_url)\n",
    "    google_url\n",
    "    response.raise_for_status()\n",
    "    response_text = response.text \n",
    "    text_list = response_text.split('</a>') \n",
    "    text_df = pd.DataFrame({'col':text_list})\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_link():\n",
    "    user_agent = get_random_ua()\n",
    "    search_term = keyword_list[number_inputs]\n",
    "    number_results = number_of_results_list[number_inputs]\n",
    "    language_code = language_code_list[number_inputs]\n",
    "    headers = {\n",
    "            'user-agent': user_agent,\n",
    "             'referrer': 'https://google.com',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Pragma': 'no-cache',\n",
    "        }\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    "    google_url = 'https://www.google.com/search?q={}&num={}&hl={}'.format(escaped_search_term, number_results, language_code)\n",
    "    print (google_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_result():\n",
    "    search_term = keyword_list[number_inputs]\n",
    "    text_df = request_link_list[number_inputs]\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    "    # Non-ad & Non-table link & with cached\n",
    "    text_df_set = text_df[text_df['col'].str.contains(\"</h3>\")]\n",
    "    if len(text_df_set) > 0:\n",
    "        text_df_set = text_df[text_df['col'].str.contains(\"</h3>\")]\n",
    "        text_df_set_2 = text_df_set['col'].str.split(\"http://webcache.googleusercontent.com/\", n = 1, expand = True)\n",
    "        text_df_set_2.columns = ['a', 'b']\n",
    "        text_df_set_3 = text_df_set_2['b'].str.split(\":\", n = 1, expand = True)\n",
    "        text_df_set_3.columns = ['a', 'b']\n",
    "        text_df_set_4 = text_df_set_3['b'].str.split(\":\", n = 1, expand = True)\n",
    "        text_df_set_4.columns = ['a', 'b']\n",
    "        text_df_set_5 = text_df_set_4['b'].str.split(\"%\", n = 1, expand = True)\n",
    "        text_df_set_5.columns = ['full link', 'b']\n",
    "        text_df_set_5 = text_df_set_5.drop(['b'], axis=1)\n",
    "        text_df_set_5 = text_df_set_5.reset_index(drop=True)\n",
    "        text_df_set_5['search term'] = search_term\n",
    "    else:\n",
    "        col_names =  ['full link', 'search term']\n",
    "        text_df_set_5  = pd.DataFrame(columns = col_names)\n",
    "        text_df_set_5.loc[len(text_df_set_5)] = ['result not found',search_term]\n",
    "        \n",
    "    # Non-ad & Non-table link & with cached    \n",
    "    text_df_wo_cache = text_df[text_df['col'].str.contains(\"q=related\")]\n",
    "    if len(text_df_wo_cache) > 0: \n",
    "        text_df_wo_cache.head()\n",
    "        text_df_wo_cache_2 = text_df_wo_cache['col'].str.split('q=related:', n = 1, expand = True)\n",
    "        text_df_wo_cache_2.columns = ['a', 'b']\n",
    "        text_df_wo_cache_3 = text_df_wo_cache_2['b'].str.split('+', n = 1, expand = True)\n",
    "        text_df_wo_cache_3.columns = ['full link', 'b']\n",
    "        text_df_wo_cache_3 = text_df_wo_cache_3.drop(['b'], axis=1)\n",
    "        text_df_wo_cache_3 = text_df_wo_cache_3.reset_index(drop=True)\n",
    "        text_df_wo_cache_3['search term'] = search_term\n",
    "    else:\n",
    "        col_names = ['full link', 'search term']\n",
    "        text_df_wo_cache_3  = pd.DataFrame(columns = col_names)\n",
    "        text_df_wo_cache_3.loc[len(text_df_wo_cache_3)] = ['result not found',search_term]\n",
    "    \n",
    "    #concating cached and similar result\n",
    "    frames = [text_df_set_5, text_df_wo_cache_3]\n",
    "    normal_result = pd.concat(frames)\n",
    "\n",
    "    #combining \n",
    "    normal_result = normal_result.drop_duplicates(subset=['full link'], keep=\"first\")\n",
    "    normal_result = normal_result.reset_index(drop = True)\n",
    "    normal_result = normal_result.dropna()\n",
    "    normal_result\n",
    "    normal_result_file_name = 'results\\\\' + escaped_search_term + '-normal+result.csv'\n",
    "    normal_result.to_csv(normal_result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_with_map():\n",
    "    search_term = keyword_list[number_inputs]\n",
    "    text_df = request_link_list[number_inputs]\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    "    # Table link\n",
    "    text_df_tab = text_df[text_df['col'].str.contains(\"<span>\")]\n",
    "    if len(text_df_tab) > 0:\n",
    "        text_df_tab_2 = text_df_tab['col'].str.split(\"<span>\", n = 1, expand = True)\n",
    "        text_df_tab_2.columns = ['a', 'b']\n",
    "        text_df_tab_3 = text_df_tab_2['b'].str.split(\"</span>\", n = 1, expand = True)\n",
    "        text_df_tab_3.columns = ['organization name', 'b']\n",
    "        text_df_tab_3 = text_df_tab_3.drop(['b'], axis=1)\n",
    "        text_df_tab_3 = text_df_tab_3.reset_index(drop=True)\n",
    "        text_df_tab_3['search term'] = search_term\n",
    "        text_df_tab_file_name = 'results\\\\' +escaped_search_term + '-with+map+result.csv'\n",
    "        text_df_tab_3.to_csv(text_df_tab_file_name)\n",
    "    else:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_with_adwords():\n",
    "    search_term = keyword_list[number_inputs]\n",
    "    text_df = request_link_list[number_inputs]\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    "    # Adwords Link \n",
    "    text_df_ad = text_df[text_df['col'].str.contains('<div class=\"ads-visurl\">')]\n",
    "    if len(text_df_ad) > 0:\n",
    "        text_df_ad_2 = text_df_ad['col'].str.split('<cite class=\"UdQCqe\">', n = 1, expand = True)\n",
    "        text_df_ad_2.columns = ['a', 'b']\n",
    "        text_df_ad_3 = text_df_ad_2['b'].str.split('</cite>', n = 1, expand = True)\n",
    "        text_df_ad_3.columns = ['a', 'b']\n",
    "        text_df_ad_3['a'] = text_df_ad_3['a'].str.replace('<b>','')\n",
    "        text_df_ad_3['a'] = text_df_ad_3['a'].str.replace('</b>','')\n",
    "        text_df_ad_3 = text_df_ad_3.drop(['b'], axis=1)\n",
    "        text_df_ad_3.columns = ['website with adword']\n",
    "        text_df_ad_3['search term'] = search_term\n",
    "        text_df_ad_3 = text_df_ad_3.reset_index(drop=True)\n",
    "        text_df_ad_file_name = 'results\\\\' +escaped_search_term + '-with+adwords+result.csv'\n",
    "        text_df_ad_3.to_csv(text_df_ad_file_name)\n",
    "    else:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "https://www.google.com/search?q=private+room+in+abu+dhabi&num=10&hl=en\n",
      "https://www.google.com/search?q=hotel+in+moscow&num=10&hl=ru\n",
      "\n",
      "\n",
      "https://www.google.com/search?q=studio+in+singapore&num=10&hl=it\n",
      "\n",
      "https://www.google.com/search?q=house+in+leuven&num=20&hl=nl\n"
     ]
    }
   ],
   "source": [
    "request_link_list =[]\n",
    "for number_inputs in range(0,len(keyword_df)):\n",
    "    request_link()\n",
    "    request_link_list.append(request_link()) \n",
    "    normal_result()\n",
    "    result_with_map()\n",
    "    result_with_adwords()\n",
    "    test_link()\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
